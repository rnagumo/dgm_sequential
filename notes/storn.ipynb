{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "pytorch",
   "display_name": "pytorch"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pixyz.distributions as pxd\n",
    "import pixyz.losses as pxl\n",
    "import pixyz.models as pxm\n",
    "import pixyz.utils as pxu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorRNN(pxd.Deterministic):\n",
    "    def __init__(self, z_dim, u_dim, h_dim):\n",
    "        super().__init__(cond_var=[\"z\", \"u\", \"h_prev\"], var=[\"h\"])\n",
    "\n",
    "        self.rnn_cell = nn.RNNCell(z_dim + u_dim, h_dim)\n",
    "\n",
    "    def forward(self, z, u, h_prev):\n",
    "        h = self.rnn_cell(torch.cat([z, u], dim=-1), h_prev)\n",
    "        return {\"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(h|z,u,h_{prev})\nNetwork architecture:\n  GeneratorRNN(\n    name=p, distribution_name=Deterministic,\n    var=['h'], cond_var=['z', 'u', 'h_prev'], input_var=['z', 'u', 'h_prev'], features_shape=torch.Size([])\n    (rnn_cell): RNNCell(5, 4)\n  )\n"
    }
   ],
   "source": [
    "print(GeneratorRNN(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(pxd.Bernoulli):\n",
    "    # TODO: `h_prev` is not updated.\n",
    "    def __init__(self, h_dim, x_dim):\n",
    "        super().__init__(cond_var=[\"h\"], var=[\"x\"])\n",
    "\n",
    "        self.fc1 = nn.Linear(h_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, x_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        probs = torch.sigmoid(self.fc3(h))\n",
    "        return {\"probs\": probs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(x|h)\nNetwork architecture:\n  Generator(\n    name=p, distribution_name=Bernoulli,\n    var=['x'], cond_var=['h'], input_var=['h'], features_shape=torch.Size([])\n    (fc1): Linear(in_features=2, out_features=512, bias=True)\n    (fc2): Linear(in_features=512, out_features=256, bias=True)\n    (fc3): Linear(in_features=256, out_features=3, bias=True)\n  )\n"
    }
   ],
   "source": [
    "print(Generator(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRNN(pxd.Deterministic):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super().__init__(cond_var=[\"x\"], var=[\"h_v\"])\n",
    "\n",
    "        self.rnn = nn.RNN(x_dim, z_dim * 2)\n",
    "        self.h0 = nn.Parameter(torch.zeros(1, 1, z_dim * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self.h0.expand(1, x.size(1), self.h0.size(2)).contiguous()\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        return {\"h_v\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(h_{v}|x)\nNetwork architecture:\n  InferenceRNN(\n    name=p, distribution_name=Deterministic,\n    var=['h_v'], cond_var=['x'], input_var=['x'], features_shape=torch.Size([])\n    (rnn): RNN(2, 6)\n  )\n"
    }
   ],
   "source": [
    "print(InferenceRNN(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(pxd.Normal):\n",
    "    def __init__(self):\n",
    "        super().__init__(cond_var=[\"h_v\"], var=[\"z\"])\n",
    "\n",
    "    def forward(self, h_v):\n",
    "        loc = h_v[:, :h_v.size(1) // 2]\n",
    "        scale = h_v[:, h_v.size(1) // 2:] ** 2\n",
    "        return {\"loc\": loc, \"scale\": scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 2\n",
    "h_dim = 4\n",
    "x_dim = 10\n",
    "u_dim = x_dim\n",
    "\n",
    "prior = pxd.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.),\n",
    "                    var=[\"z\"], features_shape=torch.Size([z_dim])).to(device)\n",
    "grnn = GeneratorRNN(z_dim, u_dim, h_dim).to(device)\n",
    "decoder = Generator(h_dim, x_dim).to(device)\n",
    "irnn = InferenceRNN(x_dim, z_dim).to(device)\n",
    "encoder = Inference().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": "$\\displaystyle - \\mathbb{E}_{p(h,z|u,h_{prev},h_{v})} \\left[\\log p(x|h) \\right]$",
      "text/plain": "<IPython.core.display.Math object>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = pxl.CrossEntropy(grnn * encoder, decoder)  #.expectation(grnn)\n",
    "pxu.print_latex(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Normal(\n  name=p, distribution_name=Normal,\n  var=['z'], cond_var=[], input_var=[], features_shape=torch.Size([2])\n  (loc): torch.Size([1, 2])\n  (scale): torch.Size([1, 2])\n)\nGeneratorRNN(\n  name=p, distribution_name=Deterministic,\n  var=['h'], cond_var=['z', 'u', 'h_prev'], input_var=['z', 'u', 'h_prev'], features_shape=torch.Size([])\n  (rnn_cell): RNNCell(12, 4)\n)\nGenerator(\n  name=p, distribution_name=Bernoulli,\n  var=['x'], cond_var=['h'], input_var=['h'], features_shape=torch.Size([])\n  (fc1): Linear(in_features=4, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=256, bias=True)\n  (fc3): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(decoder * grnn * prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 1\n",
    "\n",
    "data = {\n",
    "    \"h_prev\": torch.zeros(minibatch_size, h_dim).to(device),\n",
    "    \"u\": torch.zeros(minibatch_size, x_dim).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (decoder * grnn * prior).sample(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'h_prev': tensor([[0., 0., 0., 0.]]),\n 'u': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n 'z': tensor([[0.4675, 0.4149]]),\n 'h': tensor([[ 0.0749, -0.2037,  0.3348,  0.0514]], grad_fn=<TanhBackward>),\n 'x': tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]])}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5168, 0.5016, 0.5092, 0.5175, 0.5024, 0.4851, 0.4986, 0.4875, 0.5098,\n         0.4952]], grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.sample_mean({\"h\": sample[\"h\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(x|h)\nNetwork architecture:\n  Generator(\n    name=p, distribution_name=Bernoulli,\n    var=['x'], cond_var=['h'], input_var=['h'], features_shape=torch.Size([])\n    (fc1): Linear(in_features=4, out_features=512, bias=True)\n    (fc2): Linear(in_features=512, out_features=256, bias=True)\n    (fc3): Linear(in_features=256, out_features=10, bias=True)\n  )\n"
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.replace_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'h_prev': tensor([[0., 0., 0., 0.]]),\n 'u': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n 'z': tensor([[0.4675, 0.4149]]),\n 'h': tensor([[ 0.0749, -0.2037,  0.3348,  0.0514]], grad_fn=<TanhBackward>),\n 'x': tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]])}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-be03e0b68246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pixyz/distributions/distributions.py\u001b[0m in \u001b[0;36msample_mean\u001b[0;34m(self, x_dict)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pixyz/distributions/distributions.py\u001b[0m in \u001b[0;36mset_dist\u001b[0;34m(self, x_dict, sampling, batch_n, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/pixyz/distributions/distributions.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, params_dict)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvars_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace_dict_keys_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace_params_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvars_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'z'"
     ]
    }
   ],
   "source": [
    "decoder.sample_mean({\"z\": sample[\"z\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}